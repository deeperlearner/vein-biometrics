"""
This code is generated by Ridvan Salih KUZU @UNIROMA3
LAST EDITED:  02.03.2020
ABOUT SCRIPT:
It is a script for generating the CSV files for train/validation/test partitions from SDUMLA database images.
It is only used if open-set experimental scenario is conducted.
It only divide the first half of the database for testing and second half of it for training/validation.
The train and validation files are generated in classification mode.
The test file is generated as pairs of genuine and impostors.
"""

import os
import glob
import pandas as pd
import time
import random
import argparse

parser = argparse.ArgumentParser(description='Database Partition Generator for Open-set Scenario')

parser.add_argument('--database-dir', default='../data_sdumla/Database', type=str,
                    help='path to the database root directory')
parser.add_argument('--train-outdir', default='../CSVFiles/sdumla_train_dis.csv', type=str,
                    help='path to the CSV output file including the list of train partition')
parser.add_argument('--valid-outdir', default='../CSVFiles/sdumla_valid_dis.csv', type=str,
                    help='path to the CSV output file including the list of valid partition')
parser.add_argument('--test-outdir', default='../CSVFiles/sdumla_test_pairs_dis.csv', type=str,
                    help='path to the CSV output file including the list of test partition')

args = parser.parse_args()

def main():
    extract_train_valid_test_partitions(args.database_dir, args.train_outdir, args.valid_outdir, args.test_outdir)

def extract_train_valid_test_partitions(database_dir, train_outdir, valid_outdir, test_outdir):


    file_left = glob.glob(database_dir+"/*/left/")
    file_right = glob.glob(database_dir+"/*/right/")


    time0 = time.time()
    df_train = pd.DataFrame()
    df_val = pd.DataFrame()
    df_pos_pair=pd.DataFrame()
    df_pair=pd.DataFrame()



    pos_counter=0

    for X1,X2 in zip(file_left[0:53], file_right[0:53]):
        filx11 = glob.glob(X1 + "/index*")
        filx12 = glob.glob(X1 + "/middle*")
        filx13 = glob.glob(X1 + "/ring*")

        filx21 = glob.glob(X2 + "/index*")
        filx22 = glob.glob(X2 + "/middle*")
        filx23 = glob.glob(X2 + "/ring*")

        idx=0
        for fx11,fx12,fx13,fx21,fx22,fx23 in zip(filx11,filx12,filx13,filx21,filx22,filx23):
            idy = 0
            for fy11,fy12,fy13,fy21,fy22,fy23 in zip(filx11,filx12,filx13,filx21,filx22,filx23):
                if idx < idy:
                    df_pos_pair = df_pos_pair.append({'idx_0': fx11, 'idy_0': fy11, 'class': 1}, ignore_index=True)
                    df_pos_pair = df_pos_pair.append({'idx_0': fx12, 'idy_0': fy12, 'class': 1}, ignore_index=True)
                    df_pos_pair = df_pos_pair.append({'idx_0': fx13, 'idy_0': fy13, 'class': 1}, ignore_index=True)
                    df_pos_pair = df_pos_pair.append({'idx_0': fx21, 'idy_0': fy21, 'class': 1}, ignore_index=True)
                    df_pos_pair = df_pos_pair.append({'idx_0': fx22, 'idy_0': fy22, 'class': 1}, ignore_index=True)
                    df_pos_pair = df_pos_pair.append({'idx_0': fx23, 'idy_0': fy23, 'class': 1}, ignore_index=True)
                    pos_counter +=6
                idy += 1
            idx += 1

    filex1 = glob.glob(database_dir+"/*/left/index*")[0:318]
    filex2 = glob.glob(database_dir+"/*/right/index*")[0:318]

    filey1 = glob.glob(database_dir+"/*/left/middle*")[0:318]
    filey2 = glob.glob(database_dir+"/*/right/middle*")[0:318]

    filez1 = glob.glob(database_dir+"/*/left/ring*")[0:318]
    filez2 = glob.glob(database_dir+"/*/right/ring*")[0:318]

    filey = glob.glob(database_dir+"/*/*")
    filez = glob.glob(database_dir+"/*/*")

    files1=list(zip(filex1,filey1,filez1))
    files2=list(zip(filex2,filey2,filez2))
    random.shuffle(files1)
    random.shuffle(files2)
    neg_counter=0
    while neg_counter!=5*pos_counter:
        in_x=random.randint(0, 317)
        in_y = random.randint(0, 317)
        r_x = random.randint(0, 2)
        r_y = random.randint(0, 2)
        dice = random.randint(0, 2)
        if dice==0:
            face_labelx = os.path.dirname(files1[in_x][r_x]).split('\\')[1]
            face_labely = os.path.dirname(files1[in_y][r_y]).split('\\')[1]
            if face_labely != face_labelx:
                df_pos_pair = df_pos_pair.append({'idx_0': files1[in_x][r_x],
                                                  'idy_0': files1[in_y][r_y],
                                                  'class': 0},ignore_index=True)
                neg_counter += 1
        elif dice==1:
            face_labelx = os.path.dirname(files1[in_x][r_x]).split('\\')[1]
            face_labely = os.path.dirname(files2[in_y][r_y]).split('\\')[1]
            if face_labely != face_labelx:
                df_pos_pair = df_pos_pair.append({'idx_0': files1[in_x][r_x],
                                                  'idy_0': files2[in_y][r_y],
                                                  'class': 0},ignore_index=True)
                neg_counter += 1

        else:
            face_labelx = os.path.dirname(files2[in_x][r_x]).split('\\')[1]
            face_labely = os.path.dirname(files2[in_y][r_y]).split('\\')[1]
            if face_labely != face_labelx:
                df_pos_pair = df_pos_pair.append({'idx_0': files2[in_x][r_x],
                                                  'idy_0': files2[in_y][r_y],
                                                  'class': 0},ignore_index=True)
                neg_counter += 1



    df_pos_pair = df_pos_pair.sort_values(by=['class']).reset_index(drop=True)
    df_pos_pair.to_csv(test_outdir, index=False)



    counter = 0

    for X1, X2 in zip(file_left[53:106], file_right[53:106]):
        filx11 = glob.glob(X1 + "/index*")
        filx12 = glob.glob(X1 + "/middle*")
        filx13 = glob.glob(X1 + "/ring*")

        filx21 = glob.glob(X2 + "/index*")
        filx22 = glob.glob(X2 + "/middle*")
        filx23 = glob.glob(X2 + "/ring*")

        for fx11, fx12, fx13, fx21, fx22, fx23 in zip(filx11, filx12, filx13, filx21, filx22, filx23):
            idx = os.path.basename(fx11).split('_')[1]
            if idx == '6.bmp' or idx == '6.bmp':
                df_val = df_val.append({'idx_0': fx11, 'class': int(counter)}, ignore_index=True)
                df_val = df_val.append({'idx_0': fx12, 'class': int(counter+1)}, ignore_index=True)
                df_val = df_val.append({'idx_0': fx13, 'class': int(counter+2)}, ignore_index=True)
                df_val = df_val.append({'idx_0': fx21, 'class': int(counter)+3}, ignore_index=True)
                df_val = df_val.append({'idx_0': fx22, 'class': int(counter)+4}, ignore_index=True)
                df_val = df_val.append({'idx_0': fx23, 'class': int(counter)+5}, ignore_index=True)
            else:
                df_train = df_train.append({'idx_0': fx11, 'class': int(counter)}, ignore_index=True)
                df_train = df_train.append({'idx_0': fx12, 'class': int(counter+1)}, ignore_index=True)
                df_train = df_train.append({'idx_0': fx13, 'class': int(counter+2)}, ignore_index=True)
                df_train = df_train.append({'idx_0': fx21, 'class': int(counter+3)}, ignore_index=True)
                df_train = df_train.append({'idx_0': fx22, 'class': int(counter+4)}, ignore_index=True)
                df_train = df_train.append({'idx_0': fx23, 'class': int(counter+5)}, ignore_index=True)

        counter += 6

    df_train = df_train.sort_values(by=['class']).reset_index(drop=True)
    df_train.to_csv(train_outdir, index=False)
    df_val = df_val.sort_values(by=['class']).reset_index(drop=True)
    df_val.to_csv(valid_outdir, index=False)

if __name__ == '__main__':
    main()














